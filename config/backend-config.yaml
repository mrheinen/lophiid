backend:
  # The log level can be one of debug, info, warn and error.
  # https://pkg.go.dev/log/slog#Level
  log_level: debug
  log_file: backend.log
  downloader:
    # Location where downloaded malware will be stored.
    malware_download_dir: /home/user/malware/
    # The malware downloaded HTTP client timeout. This should be relatively high
    # because sometimes malware is served from very slow IoT devices.
    http_timeout: 10m
  listener:
    # IP and port where the backend needs to listen on.
    listen_address: localhost:41110
    # The following SSL options are optional; use them for SSL server and client
    # authentication.
    ssl_cert: path/to/server-cert.pem
    ssl_key: path/to/server-key.pem
    ssl_ca_cert: path/to/ca-cert.pem

  database:
    # URL to the postgresql database
    url: postgres://username:password@localhost/lophiid
    # How many open concurrent database connections are allowed.
    max_open_connections: 30
    # How many connections to keep open all the time.
    min_open_connections: 10

  advanced:
    # How long to cache Content's that were fetched from the database.
    content_cache_duration: 30m
    # How long to cache download URLs which prevents them from being fetched
    # again if seen multiple times in a row during this time. Don't set this
    # too long because attacker payloads change over time and it's interesting
    # to track this by refetching the same payload URLs.
    download_cache_duration: 5m
    # How long to cache ping requests. As long as a ping request is in the cache
    # no new ping requests are send.
    ping_cache_duration: 1m
    # How long before sessions expire after receiving the last request. New
    # requests reset the timeout.
    session_tracking_timeout: 15m
    # When new honeypots are registered, this content ID will be set as th
    # default content id. Absolutely make sure that this content ID exists.
    # You will want to create a content first and then put the ID here.
    honeypot_default_content_id: 77

  ratelimiter:
    rate_window: 1h
    bucket_duration: 1m
    max_ip_requests_per_window: 1000
    max_ip_requests_per_bucket: 200
    max_uri_requests_per_window: 5000
    max_uri_requests_per_bucket: 300

alerting:
  # The alerting interval.  Alerts are aggregated and send every <interval>.
  interval: 2m
  telegram:
    # Telegram API key and channel ID.
    api_key: AAAAAAAAAAAAAAAAAAAA
    channel_id: 111111

scripting:
  # A list of commands that can be called from the content javascripts.
  allowed_commands:
    - /usr/bin/false

analysis:
  # Determines how long information for an IP will be cached before
  # writing it to the database. During that time the information will be
  # updated with new events if they happen.
  ip_cache_duration: 15m
  # How many events there can be in the queue. If this is exceeded then it
  # will start blocking some logic in the backend so keep this number high
  # and monitor the queue size with prometheus/grafana.
  ip_event_queue_size: 5000
  # Determines how long (approximately) the scan detection logic will keep
  # aggregating scan events into a cached version before writing it to the db.
  # So with the default below, if there is a super slow scan, you will
  # get an event every ~1 hour.
  scan_monitor_interval: 1h

yara:
  log_file: /tmp/yara.log
  log_level: debug
  metrics_listen_address: 127.0.0.1:8997
  # The prepare command will run with one parameter which is the file that will
  # be scanned. This can be used to, for example, check if the file is packed
  # (e.g. UPX) and unpack it. When used for unpacking then the unpacked output
  # file needs to be <original_file>.unpacked
  # prepare_command:  /path/to/unpack/script.sh


  # Virustotal is optional but highly recommended.
virustotal:
  # Your virus total API key.
  api_key: AAAAAAAAAAAAAAAAAA
  # HTTP timeout for communication with virustotal.
  http_timeout: 2m
  # The time to cache URL and file scan results. Use this wisely to prevent
  # using up all your quota.
  cache_expiration_time: 96h

prometheus:
  listen_address: 127.0.0.1:8998

whois_manager:
  client_timeout: 2s
  cache_expiration_time: 12h
  max_attempts: 6

ai:
  # Whether to enable the responder.
  enable_responder: 1

  # Configure shell emulation.
  shell_emulation:
    enable: 1
    llm_manager:
      # How long prompts and responses should be cached.
      cache_expiration_time: 1h
      completion_timeout: 60s
      concurrent_requests: 5

      primary_llm:
        api_location: https://openrouter.ai/api/v1
        model: qwen/qwen3-235b-a22b-2507
        api_key: xxxxxx


  code_emulation:
    enable: 1
    llm_manager:
      # How long prompts and responses should be cached.
      cache_expiration_time: 1h
      completion_timeout: 60s
      concurrent_requests: 5

      primary_llm:
        api_location: https://openrouter.ai/api/v1
        model: qwen/qwen3-coder-30b-a3b-instruct
        api_key: xxxxxxx

  # Configure the LLM manager. You can configure it with a primary LLM and a
  # secondary LLM. If a secondary LLM is configured then the LLM Manager will
  # switch to the secondary whenever the primary is unavailable. If the primary
  # comes back then the LLM Manager will switch back (checks every X minutes).
  llm_manager:
    # How long prompts and responses should be cached. If multiple LLMs are
    # configured then the cache is shared between them.
    cache_expiration_time: 24h
    # How long a completion is allowed to take.
    completion_timeout: 60s
    # How many concurrent requests to send to the LLM API
    concurrent_requests: 5

    # The primary LLM to use for lookups.
    primary_llm:
      # API location. Use any OpenAI API endpoint.
      api_location: http://localhost:8000/v1
      api_key: AAAAAAAAAAAAAAAAAA
      # Maximum string length of the prompt input.
      max_input_characters: 4096

  triage:
    describer:
      enable: 1
      log_file: describer.log
      log_level: debug
      metrics_listen_address: x.x.x.x:8999
      cache_expiration_time: 8h

  preprocess:
    llm_manager:
      # How long prompts and responses should be cached.
      cache_expiration_time: 100h
      completion_timeout: 60s
      concurrent_requests: 5
      primary_llm:
        api_location: https://api.openai.com/v1
        model: gpt-5-nano
        api_key: xxxxx
